{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "savemodeltest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNbBCE4pUXQMolFnV0TRQXE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nateme16/geo-aquawatch-water-quality/blob/main/MDNtestsavemodeltest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Unw23quL9pN3",
        "outputId": "7f2a6291-9562-4f9e-fdd6-2016bbe180a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from pprint import pprint\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/gee-community/geo-aquawatch-water-quality/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EwJ_v4JHY7K",
        "outputId": "578c3400-d204-402d-b831-21b1b3afa939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'geo-aquawatch-water-quality'...\n",
            "remote: Enumerating objects: 70, done.\u001b[K\n",
            "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 70 (delta 22), reused 38 (delta 9), pack-reused 5\u001b[K\n",
            "Unpacking objects: 100% (70/70), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(y):\n",
        "\tprior, mu, scale = _parse_outputs(output) \n",
        "\tdistribution = 'MultivariateNormalTriL'\n",
        "\n",
        "\tdist  = getattr(tfp.distributions, distribution)(mu, scale)\n",
        "\tprob  = tfp.distributions.Categorical(probs=prior)\n",
        "\tmix   = tfp.distributions.MixtureSameFamily(prob, dist)\n",
        "\n",
        "\tdef impute(mix, y, N):\n",
        "\t\treturn tf.reduce_mean([\n",
        "\t\t\tmix.log_prob( tf.where(tf.math.is_nan(y), mix.sample(), y) )\n",
        "\t\tfor _ in range(N)], 0)\n",
        "\tlikelihood = mix.log_prob(y)\n",
        "\treturn tf.reduce_mean(-likelihood) + tf.add_n([0.])\n",
        "#\t\treturn tf.reduce_mean(-likelihood) + tf.add_n([0.] + self.model.losses)\n",
        "\n",
        "class MixtureLayer(tf.keras.layers.Layer):\n",
        "\n",
        "\tdef __init__(self, n_mix, n_targets, epsilon, **layer_kwargs):\n",
        "\t\tsuper(MixtureLayer, self).__init__()\n",
        "\t\tlayer_kwargs.pop('activation', None)\n",
        "\n",
        "\t\tself.n_mix     = n_mix \n",
        "\t\tself.n_targets = n_targets \n",
        "\t\tself.epsilon   = tf.constant(epsilon)\n",
        "\t\tself._layer    = tf.keras.layers.Dense(self.n_outputs, **layer_kwargs)\n",
        "\n",
        "\n",
        "\t@property \n",
        "\tdef layer_sizes(self):\n",
        "\t\t''' Sizes of the prior, mu, and (lower triangle) scale matrix outputs '''\n",
        "\t\tsizes = [1, self.n_targets, (self.n_targets * (self.n_targets + 1)) // 2]\n",
        "\t\treturn self.n_mix * np.array(sizes)\n",
        "\n",
        "\n",
        "\t@property \n",
        "\tdef n_outputs(self):\n",
        "\t\t''' Total output size of the layer object '''\n",
        "\t\treturn sum(self.layer_sizes)\n",
        "\n",
        "\n",
        "\t# @tf.function(experimental_compile=True)\n",
        "\tdef call(self, inputs):\n",
        "\t\tprior, mu, scale = tf.split(self._layer(inputs), self.layer_sizes, axis=1)\n",
        "\n",
        "\t\tprior = tf.nn.softmax(prior, axis=-1) + tf.constant(1e-9)\n",
        "\t\tmu    = tf.stack(tf.split(mu, self.n_mix, 1), 1) \n",
        "\t\tscale = tf.stack(tf.split(scale, self.n_mix, 1), 1) \n",
        "\t\tscale = tfp.math.fill_triangular(scale, upper=False)\n",
        "\t\tnorm  = tf.linalg.diag(tf.ones((1, 1, self.n_targets)))\n",
        "\t\tsigma = tf.einsum('abij,abjk->abik', tf.transpose(scale, perm=[0,1,3,2]), scale)\n",
        "\t\tsigma+= self.epsilon * norm\n",
        "\t\tscale = tf.linalg.cholesky(sigma)\n",
        "\n",
        "\t\treturn tf.keras.layers.concatenate([\n",
        "\t\t\ttf.reshape(prior, shape=[-1, self.n_mix]),\n",
        "\t\t\ttf.reshape(mu,    shape=[-1, self.n_mix * self.n_targets]),\n",
        "\t\t\ttf.reshape(scale, shape=[-1, self.n_mix * self.n_targets ** 2]),\n",
        "\t\t])\n",
        "\n",
        "#this is referencing the MDN model Csaba exported to the Github project and connecting the custom objects\n",
        "model = keras.models.load_model('/content/geo-aquawatch-water-quality/solids/solid_model',custom_objects={ 'loss': loss, 'MixtureLayer': MixtureLayer })\n",
        "\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ei7QS_mKJIl_",
        "outputId": "b61f18a0-61c4-4c3c-9d0c-0dccb3be8e0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f221f7ee190>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trying to create a version that I can upload with out custom objects, since, I think we dont need the loss function and the mixture layers should save in model.save in the next code block?\n",
        "model = keras.models.load_model('/content/geo-aquawatch-water-quality/solids/solid_model',compile=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "9OcF9absKAEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6rnNqHW7Cbr",
        "outputId": "005ccbc6-a5fa-47f0-fbfc-910550519c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=Iliw-EMZqMH8Uk2idX9TrNm0xc4043vhp6LvFfjkurE&code_challenge_method=S256\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below. \n",
            "Enter verification code: 4/1AX4XfWiM-zWzwtknSOY3iVDL7oIz5bT0bP4sWiOJR0-ZnFsx3JhAu0-1Juc\n",
            "\n",
            "Successfully saved authorization token.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#upload to cloud\n",
        "\n",
        "import folium\n",
        "print(folium.__version__)\n",
        "\n",
        "# REPLACE WITH YOUR CLOUD PROJECT!\n",
        "PROJECT = 'NERecreation'\n",
        "\n",
        "# Output bucket for trained models.  You must be able to write into this bucket.\n",
        "OUTPUT_BUCKET = 'eestart_nate'\n",
        "\n",
        "# This is a good region for hosting AI models.\n",
        "REGION = 'us-central1'\n",
        "\n",
        "\n",
        "MODEL_DIR = 'gs://' + OUTPUT_BUCKET + '/MDN'\n",
        "model.save(MODEL_DIR, save_format='tf')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clD_tPL76bGQ",
        "outputId": "efafdd04-d375-4dd1-9b69-dbb6e4598e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here is where I try to eefy it. Maybe the error is in this input and output dimension settings?\n",
        "\n",
        "from tensorflow.python.tools import saved_model_utils\n",
        "\n",
        "meta_graph_def = saved_model_utils.get_meta_graph_def(MODEL_DIR, 'serve')\n",
        "inputs = meta_graph_def.signature_def['serving_default'].inputs\n",
        "outputs = meta_graph_def.signature_def['serving_default'].outputs\n",
        "\n",
        "# Just get the first thing(s) from the serving signature def.  i.e. this\n",
        "# model only has a single input and a single output.\n",
        "input_name = None\n",
        "for k,v in inputs.items():\n",
        "  input_name = v.name\n",
        "  break\n",
        "\n",
        "output_name = None\n",
        "for k,v in outputs.items():\n",
        "  output_name = v.name\n",
        "  break\n",
        "\n",
        "# Make a dictionary that maps Earth Engine outputs and inputs to\n",
        "# AI Platform inputs and outputs, respectively.\n",
        "import json\n",
        "input_dict = \"'\" + json.dumps({input_name: \"array\"}) + \"'\"\n",
        "output_dict = \"'\" + json.dumps({output_name: \"TSS\"}) + \"'\"\n",
        "print(input_dict)\n",
        "print(output_dict)\n",
        "\n",
        "# Put the EEified model next to the trained model directory.\n",
        "EEIFIED_DIR = 'gs://' + OUTPUT_BUCKET + '/eeified_pixel_model'\n",
        "\n",
        "# You need to set the project before using the model prepare command.\n",
        "!earthengine set_project {PROJECT}\n",
        "!earthengine model prepare --source_dir {MODEL_DIR} --dest_dir {EEIFIED_DIR} --input {input_dict} --output {output_dict}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "tAHm05Ib74oc",
        "outputId": "70ca24c6-1625-4316-f270-a49c834e273b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-35a5c6a52fd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaved_model_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmeta_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_model_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_meta_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'serve'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature_def\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'serving_default'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature_def\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'serving_default'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MODEL_DIR' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'MDN'\n",
        "VERSION_NAME = 'v0'\n",
        "\n",
        "PROJECTID= 'ne-recreation-1545342727047'\n",
        "\n",
        "#!gcloud config set project PROJECT_ID\n",
        "\n",
        "!gcloud ai-platform models create {MODEL_NAME} \\\n",
        "  --project {PROJECTID} \\\n",
        "  --region {REGION}\n",
        "\n",
        "#I had to create the model version manually in AI platform. This code wasnt working.\n",
        "\n",
        "# !gcloud ai-platform versions create {VERSION_NAME} \\\n",
        "#   --project {PROJECTID} \\\n",
        "#   --region {REGION} \\\n",
        "#   --model {MODEL_NAME} \\\n",
        "#   --origin {EEIFIED_DIR} \\\n",
        "#   --framework \"TENSORFLOW\" \\\n",
        "#   --runtime-version=2.3 \\\n",
        "#   --python-version=3.7\n",
        "\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TryIGkYK74mW",
        "outputId": "76752e4c-9635-419c-ff5c-f70ca3798ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
            "\u001b[1;31mERROR:\u001b[0m (gcloud.ai-platform.models.create) Resource in projects [ne-recreation-1545342727047] is the subject of a conflict: Field: model.name Error: A model with the same name already exists.\n",
            "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
            "  fieldViolations:\n",
            "  - description: A model with the same name already exists.\n",
            "    field: model.name\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Put the EEified model next to the trained model directory.\n",
        "EEIFIED_DIR = 'gs://' + OUTPUT_BUCKET + '/eeified_pixel_model'\n",
        "print(EEIFIED_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4095mNaCfTNJ",
        "outputId": "37ee0d0d-3bd2-4e7b-ad50-0a730f35b874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gs://eestart_nate/eeified_pixel_model\n"
          ]
        }
      ]
    }
  ]
}
